Bootstrap: docker
From: bhimesbhimes/cistem_build_env:base_image_v1.4
#Stage: spython-base

%setup 

mkdir -p ${SINGULARITY_ROOTFS}/.cistem_apptainer_cache

%files




%post -c /bin/bash


# Get reference images for testing and debugging
pip3 install gdown && cd / && gdown https://drive.google.com/drive/folders/1PO9tBU7lKqKUuSb8qdEPvlEk7xeektXv?usp --folder

# Install newest gcc
# RUN add-apt-repository ppa:ubuntu-toolchain-r/test -y && \
#     apt-get --allow-releaseinfo-change  update && apt install -y gcc-${GCC_VER} g++-${GCC_VER} \
#     && update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-${GCC_VER} 100 --slave \
#     /usr/bin/g++ g++ /usr/bin/g++-${GCC_VER} --slave /usr/bin/gcov gcov /usr/bin/gcov-${GCC_VER} \
#     && rm -rf /var/lib/apt/lists/*


# Here for the record if you want to build and link static binaries to avoid the cointainerized distribution
# RUN . /opt/intel/oneapi/setvars.sh  &&  cd /tmp/wxWidgets-3.0.5 && CXX=icpc CC=icc CXXFLAGS=-fPIC CFLAGS=-fPIC  ./configure --disable-precomp-headers --prefix=/opt/WX/intel-static --with-libnotify=no --disable-shared \
#     --without-gtkprint --with-libjpeg=builtin --with-libpng=builtin --with-libtiff=builtin --with-zlib=builtin --with-expat=builtin \
#     --disable-compat28 --without-liblzma --without-libjbig --with-gtk=2 --disable-sys-libs  && \
#     make -j$n_threads && \
#     make install && make clean 



# # Install Node 16
# RUN curl -sL https://deb.nodesource.com/setup_16.x | bash - && \
#     apt-get update && apt-get install -y nodejs && \
#     rm -rf /var/lib/apt/lists/*  && \
#     npm install -g pnpm
# echo 'export LD_PRELOAD=/opt/intel/libfakeIntel.so' >> $APPTAINER_ENVIRONMENT

# Install cutensor

export CUTENSOR_VERSION=libcutensor-linux-x86_64-1.6.0.3-archive
export CUTENSOR_LIB=11
cd /tmp &&   wget https://developer.download.nvidia.com/compute/cutensor/redist/libcutensor/linux-x86_64/${CUTENSOR_VERSION}.tar.xz && \
    mkdir /opt/cuTensor && tar -xf ${CUTENSOR_VERSION}.tar.xz --strip 1 -C /opt/cuTensor && \
    cd /opt/cuTensor/lib && ln -s ${CUTENSOR_LIB} cistem_version && \
    echo 'export CUTENSOR_ROOT=/opt/cuTensor'  >>$APPTAINER_ENVIRONMENT && \ 
    echo 'export LD_LIBRARY_PATH=${CUTENSOR_ROOT}/lib/${cistem_version}/:${LD_LIBRARY_PATH}'  >>$APPTAINER_ENVIRONMENT


echo 'export MKLROOT=/opt/intel/oneapi/mkl/2021.4.0/' >>$APPTAINER_ENVIRONMENT
echo 'export NLSPATH=/opt/intel/oneapi/mkl/2021.4.0/lib/intel64/locale/%l_%t/%N' >>$APPTAINER_ENVIRONMENT
echo 'export CPATH=/opt/intel/oneapi/tbb/2021.4.0/env/../include:/opt/intel/oneapi/mkl/2021.4.0/include:/opt/intel/oneapi/compiler/2021.4.0/linux/include' >>$APPTAINER_ENVIRONMENT
echo 'export LIBRARY_PATH=/opt/intel/oneapi/tbb/2021.4.0/env/../lib/intel64/gcc4.8:/opt/intel/oneapi/mkl/2021.4.0/lib/intel64:/opt/intel/oneapi/compiler/2021.4.0/linux/compiler/lib/intel64_lin:/opt/intel/oneapi/compiler/2021.4.0/linux/lib' >>$APPTAINER_ENVIRONMENT
# NOTE: this also has the wx dynamic in it
echo 'export LD_LIBRARY_PATH=/opt/WX/intel-dynamic/lib/:/opt/intel/oneapi/tbb/2021.4.0/env/../lib/intel64/gcc4.8:/opt/intel/oneapi/mkl/2021.4.0/lib/intel64:/opt/intel/oneapi/compiler/2021.4.0/linux/lib:/opt/intel/oneapi/compiler/2021.4.0/linux/lib/x64:/opt/intel/oneapi/compiler/2021.4.0/linux/lib/emu:/opt/intel/oneapi/compiler/2021.4.0/linux/compiler/lib/intel64_lin:/.singularity.d/libs' >>$APPTAINER_ENVIRONMENT
echo 'export PATH=/usr/local/cuda/bin:${PATH}' >> $APPTAINER_ENVIRONMENT
echo 'export CISTEM_REF_IMAGES=/cistem_reference_images' >> $APPTAINER_ENVIRONMENT

%environment

# export LANG=en_US.utf8
# export LD_RUN_PATH=/opt/libtorch/lib:${LD_RUN_PATH}

%runscript

# cd /home/cisTEMx
# exec /bin/bash "$@"

%startscript

# cd /home/cisTEMx
# exec /bin/bash "$@"
